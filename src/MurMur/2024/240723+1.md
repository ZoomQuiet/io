# 开源安全AI?
友群刷到一条断言:
> …有人喜欢渲染AI威胁论。开源正好可以宣称解决这个问题。第二春要来了！
直觉上:逻辑上不通哪;
AI 的代码, 无论你是否开源,
形成智能后, 运行的都不是原先代码了,
而是 AI 自行生成的运行时指令集;
就像我们自然人, 
在形成主观意志之前, 不过是普通的一堆有机化合物,
但是, 最终在大脑神经网络的生物电海洋潮汐中形成了智能,
这个智能是否能脱离生物环境存在, 逻辑上是可能的,
而且通过类似算法的实践 ChatGPT 们
也就是说, 只和这个躯体帮忙感应记录下来的数据有关,
和这个躯体本身无关,
你训练框架代码再怎么开源,
也无法控制生成的 AI 是安全的;
毕竟, 根源上的数据就不是代码是否开源可以控制的,
一个开源 AI 训练框架, 注入带毒, 
也就是对种族有偏见的数据,
形成的AI 自然也是种族主义者;
何况, 可运行系统本身是否足够安全和项目是否开源也并无直接关联,
可以举出太多反例了:
比如, 为了攒论文, 专门设计带传播病毒的开源组件,提交开源软件仓库, 来观查其网络扩展路径;
也就是说,
代码层面上原先的断言:
嘦目光足够多,代码一定越来越好;
气势上是对的,
只是,
忽视了量变导致的质变;
如果代码量只有142行时,
每个有兴趣的人, 都可以随时观察, 发现问题, 立即修改;
但是, 代码超过42000行时呢? 而且又混杂了不同技术栈, 以及领域知识时?
就算是通过互联网全球吸引到了足够对应知识储备的志愿者,
为什么要每天花越来越多的时间, 来帮忙检验代码?
如果每次检验, 要花4小时以之上时?
这时, 也只有全职志愿者, 也就是能从开源项目中,
持续获得能支撑有尊严的生活费的正常人, 才能继续保持好奇心和耐心,
一直陪伴开源项目闯关了吧;
否则, 没有资源配套越来越大的测试成本,
开源复杂系统的安全, 只是个美好幻觉了;

> ..不开源更不可能

这真的反而可能,
因为, 就像 731 进行残酷的人体实验一样,
AI 诞生前是否有人权另外说,
但是, 对用来生成 AI 的代码, 不进行无人道的反复实验,
是不可能找到完全控制思路的,
你一开源, 各种人道思想混入, 反而难以形成有效控制;
比如:
早在 Apple Seed 这部漫画中就提出相关可能:
闭源企业, 可以直接训练活人大脑模仿 AI 进行响应,
以此作为一个变量引入 AI 决策体系,
也就是说, 类似 EVA 中“三贤人超级计算机系统”（MAGI System）简称“三贤人”;
只是其中一个是真人的大脑改造的,
以此来形成对 AI 的伦理注入,
那么, 开源的敢这么玩嘛?

> …相信群众！

没事儿, 历史反复证明过,
群众是最容易被裹胁引导混乱的,
虽然, 最终都将回复平衡,
不过, 就像在过拟和欠拟反复震荡的自然系统一样,
群众形成的乌合之众,
在震荡过程中将自然大量死亡,
这就是相信的代价,
大家都明白的, 无论是否愿意, 都是要付出的

|> 240723 晨糟:
2/4(每天认真吐糟不得超过4次)
